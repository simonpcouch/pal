---
title: "Getting started with pal"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Getting started with pal}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

Pals are persistent, ergonomic LLM assistants designed to help you complete repetitive, hard-to-automate tasks quickly.

```r
library(pal)
```

The pal package ships with a number of pre-engineered "roles." A pal role is a keyword that succinctly describes what the pal is intended to do and serves as an identifier to match the pal with its _prompt_ and _interface_. A pal's prompt is just a markdown file with enough context and examples to teach a model to carry out a given task well. A pal's interface determines whether it replaces, prefixes, or suffixes the selected code. For example:

* The `"testthat"` pal helps you transition your R package's unit tests to the third edition of testthat. Its prompt shows the model how to convert to snapshot tests, disentangle nested expectations, and transition from deprecated functions. It replaces the selected code.
* The `"roxygen"` pal helps you quickly template out royxgen documentation for a function. Its prompt shows the model how to write high-quality stub `@param` and `@returns` entries that can be later extended by the developer. It prefixes the selected code.

## Choosing a model

The pal addin supports any model supported by [ellmer](https://ellmer.tidyverse.org/). When choosing a model for use with pal, you'll want to the use the most performant model possible that satisfies your privacy needs; pal automatically passes along your selected code to your chosen model, so it's especially important to consider data privacy when using LLMs with pal.

pal uses the `.pal_chat` option to configure which model powers the addin. `.pal_chat` is a function that returns an ellmer Chat object. For example, to use OpenAI's GPT-4o-mini, you might write `options(.pal_chat = function() ellmer::chat_claude())`. Paste that code in your `.Rprofile` via `usethis::edit_r_profile()` to always use the same model every time you start an R session.

If you're using ellmer inside a organization, you'll be limited to what your IT department allows, which is likely to be one provided by a big cloud provider, e.g. `chat_azure()`, `chat_bedrock()`, `chat_databricks()`, or `chat_snowflake()`. If you're using ellmer for your own exploration, you'll have a lot more freedom, so we have a few recommendations to help you get started:

- As of early 2025, Anthropic's **Claude Sonnet 3.5** is a very powerful model for code assistance and is the model I've used while developing the package. If you want to use Claude, you'll need to register an [API key](https://console.anthropic.com/) to the environment variable `ANTHROPIC_API_KEY` and then set `options(.pal_chat = function() ellmer::chat_claude())`. 

* Regarding OpenAI's models, `chat_openai()` defaults to **GPT-4o**, but you can use `model = "gpt-4o-mini"` for a cheaper, lower-quality model; to use an OpenAI model, you'll need to set the options `options(.pal_chat = function() ellmer::chat_openai(model = "gpt-4o"))` and register your OpenAI API key with the `OPENAI_API_KEY` environment variable.

- You can use a **local model** with `chat_ollama()`, which uses [Ollama](https://ollama.com) and allows you to run models on your own computer. While the biggest models you can run locally aren't as good as the state of the art hosted models, they don't share your data and are effectively free. To use an ollama model, run the model locally and then set `options(.pal_chat = function() ellmer::chat_ollama(model = "model-name"))`. Instead of `model-name`, you'd substitute in the name of the model that appears when you run `ollama list` at the console.

## The pal addin

Rather than through package functions directly, pals are interfaced with via the pal addin. Once you have a default model set up, you're ready to use the package in any RStudio session (even if you haven't loaded the package yet).

Just:

* Select some code.
* Trigger the pal addin.
* Type in a pal "role." Once it's autocompleted, press Enter.
* Watch your code be rewritten.

```{r}
#| fig-alt: "A screencast of an RStudio session. An .R file is open in the editor with a function definition. The user selects various subsets of the function and, after selecting from a dropdown menu, the pal assistant converts erroring code and drafts function documentation."
knitr::include_graphics("https://raw.githubusercontent.com/simonpcouch/pal/refs/heads/main/inst/figs/addin.gif")
```

Pals are interfaced with the via the pal addin. For easiest access, we recommend registering the pal addin to a keyboard shortcut.

**In RStudio**, navigate to `Tools > Modify Keyboard Shortcuts > Search "Pal"`â€”we suggest `Ctrl+Alt+P` (or `Ctrl+Cmd+P` on macOS).

**In Positron**, you'll need to open the command palette, run "Open Keyboard Shortcuts (JSON)", and paste the following into your `keybindings.json()`:

```json
    {
        "key": "Ctrl+Cmd+P",
        "command": "workbench.action.executeCode.console",
        "when": "editorTextFocus",
        "args": {
            "langId": "r",
            "code": "pal::.init_addin()",
            "focus": true
        }
    }
```

The analogous keybinding on non-macOS is `Ctrl+Alt+P`. That said, change the `"key"` entry to any keybinding you wish!

Once those steps are completed, you're ready to use pals with a keyboard shortcut.

## Adding custom pals

While the pal package comes with three pals for package development, one can use pals for all sorts of coding tasks in R, from interactive data analysis to authoring with Quarto, or even for coding tasks in languages other than R! All you need to set up your own pal is a markdown file.

To learn more about adding custom pals as well as how to share them with others, see the ["Custom pals" vignette](custom.html) with `vignette("custom", package = "pal")`.
